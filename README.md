# CompAIon â€” Offline AI for Android

CompAIon is an offline-first Android assistant that runs speech-to-text, LLM inference, and text-to-speech fully on-device. It is wired for the Astral Pirates control stack and mirrors the visual language used in the Control deck (`https://astralpirates.com/gangway/engineering/control`).

**Download E.L.S.A. for Android:** [E.L.S.A.](https://github.com/RA-moon/CompAIon/releases/latest)

## GitHub Project Description (Copy/Paste)
- Short description: `Offline AI assistant for Android: on-device Whisper STT + MLC LLM + Android TTS, with a stylized control-deck UI.`
- Topics: `android`, `offline-ai`, `on-device-ml`, `whisper`, `mlc-llm`, `tts`, `kotlin`, `jni`, `filament`
- Extended description: `docs/PROJECT_DESCRIPTION.md`

## What It Does Today
- Push-to-talk (PTT) recording at 16 kHz mono PCM16.
- On-device speech-to-text via `whisper.cpp` through JNI.
- On-device LLM responses via `mlc4j` (MLC LLM runtime).
- On-device text-to-speech using Android TTS (German locale).
- Astral Pirates-inspired UI with SceneView + Filament 3D models.

## System Architecture

```text
Press + hold PTT
  -> AudioRecorder records PCM16
  -> WavWriter produces ptt.wav (16 kHz mono)
  -> WhisperBridge (JNI)
  -> whisper.cpp transcribes (de)
  -> MlcEngine streams a short German answer
  -> TtsEngine speaks the answer
```

Key orchestration lives in `app/src/main/java/com/example/offlinevoice/AssistantController.kt`.

## Repo Structure (High Signal Paths)
- Android app module: `app`
- Voice pipeline (Kotlin): `app/src/main/java/com/example/offlinevoice`
- Native STT bridge (C++/JNI): `app/src/main/cpp/native-lib.cpp`
- Native build graph (CMake): `app/src/main/cpp/CMakeLists.txt`
- Whisper submodule: `app/src/main/cpp/whisper.cpp`
- 3D assets: `app/src/main/assets/models`

## Prerequisites
- Android Studio with SDK 34+ installed.
- Android NDK + CMake installed via SDK Manager.
- `adb` available on your PATH.
- Sibling repo present at `../mlc-llm` (this project includes `:mlc4j` from that checkout).

## One-Time Setup

### 1) Sync submodules

```bash
git submodule update --init --recursive
```

### 2) Ensure `mlc-llm` is checked out next to this repo

This project expects:

```text
../mlc-llm/android/mlc4j
```

That wiring is configured in `settings.gradle.kts`.

## Models and Assets

### Whisper model (STT)
Gradle copies the bundled Whisper model into generated assets during `preBuild`:
- Source: `app/src/main/cpp/whisper.cpp/models/ggml-base.bin`
- Generated asset: `app/build/generated/assets/whisper/models/ggml-base.bin`
- Runtime install target: `files/models/stt/ggml-base.bin`

The copy task is defined in `app/build.gradle.kts` as `prepareWhisperModel`.

### MLC model (LLM)
The assistant looks for an installed MLC model at runtime under either:
- `/sdcard/Android/data/com.example.offlinevoice/files/models/llm/<model>`
- `files/models/llm/<model>`

Model resolution and runtime validation live in `app/src/main/java/com/example/offlinevoice/MlcEngine.kt`.

To install the packaged model via Gradle:

```bash
./gradlew :app:installDebugWithModel
```

Detailed CPU/GPU setup notes and the full Android MLC runbook live in:
- `docs/MLC_ANDROID_CPU_RUNBOOK.md`

Useful related tasks:

```bash
./gradlew :app:prepareMlcAppConfig
./gradlew :app:installMlcModel
```

## Build and Run

```bash
./gradlew :app:assembleDebug
./gradlew :app:installDebugWithModel
```

If you just want the APK:

```bash
./gradlew :app:assembleDebug
```

## Distribution (APK + Store)
- Release checklist: `docs/STORE_RELEASE_CHECKLIST.md`

## How The Voice Pipeline Is Wired

### Audio capture
- `AudioRecorder` records raw PCM to a temp file.
- `WavWriter` wraps that PCM into a valid WAV container.
- Output lives at `cacheDir/ptt.wav`.

### Speech-to-text (STT)
- `WhisperBridge` loads `native-lib` and calls JNI.
- `native-lib.cpp` validates the model and WAV format before inference.
- Whisper runs with `language = "de"` and greedy decoding.

### LLM response
- `MlcEngine` discovers an installed model, verifies the runtime, and streams tokens.
- The system prompt is intentionally strict: short, direct German responses.

### Text-to-speech (TTS)
- `TtsEngine` uses Android's `TextToSpeech` with `Locale.GERMAN`.

## UI and Astral Pirates Styling
The UI deliberately mirrors Astral Pirates Control aesthetics:
- Transparent SceneView layered over gradients and haze.
- Filament material tuning for glassy transmission.
- Animated gradient text and frosted panels.

Start here for visual tuning:
- Scene setup: `app/src/main/java/com/example/offlinevoice/MainActivity.kt`
- Material tuning: `buildValuesMaterial(...)` and `tuneAstralLighting(...)`
- Layout: `app/src/main/res/layout/activity_main.xml`

## Operational Notes
- Model integrity is checked both in Kotlin and in JNI (size + ggml magic).
- The pipeline is serialized through a single-thread executor to avoid overlap.
- Errors are surfaced to both UI and TTS to keep the experience debuggable without logs.

## Troubleshooting
- "Kein MLC-Modell gefunden": the model folder is not installed where `MlcEngine` expects it.
- "MLC Runtime nicht gefunden": `:mlc4j` native artifacts are not being packaged.
- "(wav read failed - expected 16kHz mono PCM16)": the recorder output format drifted.
- "(model invalid - expected ggml .bin)": the Whisper model did not copy or is corrupted.

For logs during device runs:

```bash
adb logcat | rg "CompAIon|MLC|whisper"
```

## Why This Repo Scores Well (And How To Push It Further)
GitRoll rewards clear architecture, cross-domain integration, and documentation. This repo shows all three:
- Architecture: explicit controller orchestration and strict model validation boundaries.
- Cross-domain: Android UI + JNI C++ + on-device STT + on-device LLM + TTS.
- Documentation: this README points directly at the decision-making hotspots.

Fast ways to boost the score further:
- Add a short demo clip or GIF and reference it here.
- Add a simple instrumentation smoke test for the PTT flow.
- Publish a release tag after each meaningful milestone.
